# -*- coding: utf-8 -*-
"""valued shopper_v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RFrCCVXDOExH1uukYduGwWmWynnOQZNq
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd
import gzip
import multiprocessing
import pandas as pd
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle competitions download acquire-valued-shoppers-challenge

with gzip.open('offers.csv.gz') as f:

    offers = pd.read_csv(f)

offers.head()

print(offers.shape)
offers.isnull().sum()

with gzip.open('trainHistory.csv.gz') as f:

    trainHistory = pd.read_csv(f)

trainHistory.head()

print(trainHistory.shape)
trainHistory.isnull().sum()

offers.value_counts()

offers.nunique()

sns.histplot(offers.offer)

offers.describe()

trainHistory.nunique()

trainHistory.describe()

history = trainHistory.merge(offers, on='offer')
print(history.shape)
history.head(5)

fig, ax =plt.subplots(1, figsize=(20,5))
sns.boxplot(x = history.offer, y = history.repeattrips)
plt.tight_layout()

history.describe()

history.offerdate.max()

history.offerdate.min()

history.to_csv("History.csv", index=False, encoding='utf-8-sig')

from google.colab import files
files.download('History.csv')

history.head()

history.drop(['z_score'],axis=True)

history.isnull().sum()

comp_tmp = history.company
 comp_tmp = comp_tmp.unique()
 comp_tmp = set(comp_tmp)

 brand_tmp = history.brand
 brand_tmp = brand_tmp.unique()
 brand_tmp = set(brand_tmp)

 cat_tmp = history.category
 cat_tmp = cat_tmp.unique()
 cat_tmp = set(cat_tmp)

chunk_size = 2 * (10 ** 7)
no_entries = 0
for chunk in pd.read_csv('transactions.csv.gz', compression = 'gzip', chunksize = chunk_size,
                        engine='c'):
    no_entries += chunk.shape[0]
    print(chunk.shape)
print(no_entries)

import glob
 import pandas as pd
 extension = 'csv'
 all_filenames = [i for i in glob.glob('*.{}'.format(extension))]
 offer_transactions = pd.concat([pd.read_csv(f) for f in all_filenames ])
 #export to csv
 offer_transactions.to_csv( "Final.csv", index=False, encoding='utf-8-sig')

offer_transactions = pd.read_csv('Final.csv')
offer_transactions.date = pd.to_datetime(offer_transactions.date)
print(offer_transactions.shape)
offer_transactions.head()

df = pd.read_csv('/content/transactions_offer_0.csv')

df.head(1)

df.shape

print(df['date'].max())
print(df['date'].min())

chunk.shape

chunk.head()

chunk['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')

chunk.head()

# Filter data between two dates
filtered_chunk = df.loc[(df['date'] >= '2013-03-01')  & (df['date'] < '2013-04-30')]

filtered_chunk.shape

filtered_chunk.head()

filtered_chunk.to_csv( "Final1.csv", index=False, encoding='utf-8-sig')

